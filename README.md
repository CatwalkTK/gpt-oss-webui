# Clavi Local Mining with Vector Search RAG

Clavi Local Mining is a modern ChatGPT-style interface built with Next.js 15 and React 19, featuring advanced **Vector Search RAG (Retrieval-Augmented Generation)** capabilities for local document indexing and intelligent search.

## ğŸš€ Features

### Core Chat Functionality
- **Real-time AI Chat**: Interactive conversations with streaming responses
- **Multiple Chat Management**: Manage multiple simultaneous conversations
- **Custom GPTs**: Create and manage personalized AI assistants
- **Conversation Starters**: Pre-defined prompts for quick chat initiation
- **Multimodal Support**: Handle images, PDFs, and Office documents
- **Inline Document Search**: Toggle a vector-search panel inside the chat, feed results straight into responses, or disable indexed context entirely for pure chat
- **Customisable Language Mode**: Choose the assistant's reply language from the Settings panel
- **Flexible Preferences**: Adjust theme, sidebar position, and interface size directly from the sidebar

### ğŸ” Advanced Vector Search & RAG
- **Local Document Indexing**: Index your files locally using vector embeddings
- **Intelligent Search**: AI-powered semantic search through your documents
- **Context-Aware Responses**: AI answers enriched with relevant document content
- **Real-time Document Processing**: Automatic text extraction and chunking
- **Browser-based Storage**: All data stored locally using IndexedDB

### ğŸ“ Supported File Types
- **Text Files**: `.txt`, `.md`, `.js`, `.ts`, `.jsx`, `.tsx`, `.py`, `.java`, `.cpp`, `.c`
- **Web Files**: `.html`, `.css`, `.json`, `.xml`, `.yml`, `.yaml`, `.sql`
- **Scripts**: `.sh`, `.bat`, `.php`, `.rb`, `.go`, `.rs`, `.swift`
- **Documents**: `.pdf`, `.docx`, `.doc`, `.xlsx`, `.xls`, `.pptx`, `.ppt`

### ğŸŒ Language Support
- **Japanese Language**: Full support for Japanese text processing and OCR
- **Multilingual**: Supports multiple languages with intelligent context switching
- **IME Integration**: Prevents accidental message sending during Japanese input

## ğŸ—ï¸ Technical Architecture

### Frontend Stack
- **Next.js 15**: React 19-based modern web framework
- **TypeScript**: Type-safe development environment
- **Tailwind CSS**: Custom styling system
- **KaTeX**: Beautiful mathematical notation rendering
- **Heroicons**: Comprehensive icon library

### AI & Search Stack
- **Ollama Integration**: Local AI model execution
- **Vector Embeddings**: `nomic-embed-text` for document embeddings
- **Cosine Similarity**: Semantic search algorithm
- **IndexedDB**: Browser-native vector storage
- **Streaming API**: Real-time response generation

### RAG Implementation
```
Document â†’ Text Extraction â†’ Chunking â†’ Embedding â†’ Vector Store
                                                          â†“
User Query â†’ Embedding â†’ Similarity Search â†’ Context Injection â†’ AI Response
```

## ğŸ“¦ Installation

### Prerequisites
- **Node.js 18+**
- **Ollama** (for local AI execution)

### Setup
1. **Clone the repository**
   ```bash
   git clone https://github.com/CatwalkTK/gpt-oss-webui.git
   cd gpt-oss-webui
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Install AI models**
   ```bash
   # Chat model (choose one)
   ollama pull deepseek-r1:7b
   
   # Embedding model (required for vector search)
   ollama pull nomic-embed-text
   ```

4. **Start development server**
   ```bash
   npm run dev
   ```

5. **Access the application**
   - Main chat: http://localhost:3000
   - Vector search: http://localhost:3000/search
   - Custom GPTs: http://localhost:3000/mygpts

## ğŸ¯ Usage Guide

### Basic Chat
1. Navigate to the main page
2. Click "Start a new chat"
3. Type your message and press Enter
4. Enjoy streaming AI responses

### Document Search & RAG
1. **Open the Document Search tools**:
   - From the main chat, use the **Show Document Search** toggle in the header, or
   - Visit the dedicated page at http://localhost:3000/search

2. **Index your documents**:
   - **Option A**: Click "Index Folder" (Chrome/Edge only)
   - **Option B**: Click "Add Files" for individual files
   - **Option C**: Drag & drop files directly

3. **Search documents**:
   - Use the search bar to find relevant content
   - View similarity scores and document previews

4. **Chat with context**:
   - Once documents are indexed, every chat message automatically runs a semantic lookup
   - Relevant passages are injected into the prompt, even when you stay on the main chat view
   - Responses include pointers to the matched documents whenever possible

### Settings
1. Expand **Preferences** in the sidebar footer
2. Choose your reply **language**, toggle the **theme** (dark/light), switch the sidebar **position**, adjust the interface **size**, or disable **indexed context** when you want pure conversations
3. Use the `/settings` page when you need to review storage usage or clear saved chats

### Custom GPTs
1. Navigate to "My GPTs"
2. Click "Create a GPT"
3. Configure name, description, instructions, and conversation starters
4. Use your custom GPT for specialized tasks

## ğŸ”§ Configuration

### Environment Variables
```env
NEXT_PUBLIC_API_URL=http://localhost:11434  # Ollama API endpoint
```

### Model Configuration
Update `src/lib/constants.ts`:
```typescript
export const API_CONFIG = {
  DEFAULT_MODEL: 'deepseek-r1:7b',  # Your preferred chat model
  EMBEDDING_MODEL: 'nomic-embed-text'  # Embedding model for vector search
}
```

## ğŸ—‚ï¸ Project Structure

```
gpt-oss-webui/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                    # Next.js App Router pages
â”‚   â”‚   â”œâ”€â”€ page.tsx           # Main chat interface
â”‚   â”‚   â”œâ”€â”€ search/            # Vector search & RAG page
â”‚   â”‚   â””â”€â”€ mygpts/           # Custom GPT management
â”‚   â”œâ”€â”€ components/            # React components
â”‚   â”‚   â”œâ”€â”€ VectorSearch.tsx  # Document indexing & search UI
â”‚   â”‚   â”œâ”€â”€ MessageBubble.tsx # Chat message display
â”‚   â”‚   â””â”€â”€ ChatInput.tsx     # Message input with file support
â”‚   â”œâ”€â”€ hooks/                 # React hooks
â”‚   â”‚   â”œâ”€â”€ useVectorSearch.ts # Vector search functionality
â”‚   â”‚   â”œâ”€â”€ useChatWithRAG.ts # RAG-enhanced chat
â”‚   â”‚   â””â”€â”€ useChat.ts        # Standard chat functionality
â”‚   â”œâ”€â”€ lib/                   # Core services
â”‚   â”‚   â”œâ”€â”€ vectorStore.ts    # IndexedDB vector storage
â”‚   â”‚   â”œâ”€â”€ embeddingService.ts # AI embedding generation
â”‚   â”‚   â”œâ”€â”€ documentIndexer.ts # Document processing
â”‚   â”‚   â””â”€â”€ ragApi.ts         # RAG API integration
â”‚   â””â”€â”€ types/                 # TypeScript type definitions
â”œâ”€â”€ public/                    # Static assets
â””â”€â”€ package.json              # Dependencies and scripts
```

## ğŸŒŸ Key Components

### Vector Search System
- **VectorStore**: IndexedDB-based local vector database
- **EmbeddingService**: AI-powered text embedding generation
- **DocumentIndexer**: File processing and chunking system
- **RAG API**: Context-aware response generation

### Chat System
- **Message Streaming**: Real-time response display
- **File Attachments**: Multimodal conversation support
- **Context Management**: Intelligent conversation history
- **Custom GPTs**: Personalized AI assistant creation

## ğŸ” Browser Compatibility

### Directory Picker (Full folder indexing)
- âœ… **Google Chrome 86+**
- âœ… **Microsoft Edge 86+**
- âŒ Firefox, Safari (use "Add Files" instead)

### File Upload & Core Features
- âœ… **All modern browsers**
- âœ… **Drag & drop support**
- âœ… **IndexedDB storage**

## ğŸš€ Performance

### Indexing Performance
- **Text files**: ~100-500 files/minute
- **Binary files**: Slower, depends on size
- **Chunk size**: 500 characters (configurable)
- **Embedding generation**: ~100ms per chunk

### Search Performance
- **Vector similarity**: Real-time (<100ms)
- **Result ranking**: Cosine similarity based
- **Context retrieval**: Top-K relevant chunks

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project uses a **Triple License** system for maximum protection:

### ğŸ”“ **Open Source License: AGPL-3.0**
- âœ… **Personal, Educational & Research**: Free to use, modify, and distribute
- âœ… **Network Services**: Must provide source code to all users
- âœ… **Modifications**: Must be released under AGPL-3.0
- âŒ **Commercial Closed-Source**: Not permitted under this license

### ğŸ’¼ **Commercial License: Available**
- âœ… **Proprietary Integration**: No source code disclosure required
- âœ… **Commercial Services**: SaaS, enterprise deployments allowed
- âœ… **Closed-Source Distribution**: Full commercial rights
- âœ… **Premium Support**: Technical support and warranties included

### ğŸ“š **Documentation License: CC BY-NC-SA 4.0**
- âœ… **Share & Adapt**: For non-commercial purposes
- âœ… **Attribution Required**: Must credit the original author
- âŒ **Commercial Use**: Requires separate permission

---

### ğŸ¤ **Choose Your License**

| Use Case | License Required | Contact |
|----------|------------------|---------|
| **Personal/Educational** | AGPL-3.0 (Free) | Use freely |
| **Open Source Project** | AGPL-3.0 (Free) | Must share improvements |
| **Commercial Product** | Commercial License | [Get Commercial License](mailto:tsuda@ryowa-inc.co.jp) |
| **Enterprise/SaaS** | Commercial License | [Enterprise Inquiry](mailto:tsuda@ryowa-inc.co.jp) |

### ğŸ’¡ **Why This License Structure?**

This **Triple License** approach ensures:
- ğŸŒŸ **Innovation Protection**: Your advanced RAG technology remains protected
- ğŸ’° **Revenue Opportunity**: Commercial users pay for the value they receive
- ğŸ¤ **Community Growth**: Open source community can still benefit and contribute
- âš–ï¸ **Legal Clarity**: Clear terms prevent licensing confusion

**Questions about licensing?** Contact: [tsuda@ryowa-inc.co.jp](mailto:tsuda@ryowa-inc.co.jp)

See [LICENSE](./LICENSE) file for full terms and conditions.

## ğŸ™ Acknowledgments

- **Ollama** for local AI model execution
- **Next.js** team for the excellent framework
- **Nomic AI** for the embedding model
- **OpenAI** for API compatibility standards
